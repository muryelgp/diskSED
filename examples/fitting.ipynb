{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "331585ab-7446-4787-9c71-c105f6448e4e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Fitting X-ray Spectrum + Opt/UV SED with diskSED\n",
    "\n",
    "===========================================================\n",
    "\n",
    "This notebook will go over how to load, configure, and fit (in a Bayesian framework) the full SED. It will make use of three pieces of software:\n",
    "* pyXSPEC: https://heasarc.gsfc.nasa.gov/xanadu/xspec/python/html/ \n",
    "* Bayesian X-ray Analysis (BXA): https://johannesbuchner.github.io/BXA/index.html\n",
    "* UltraNest: https://johannesbuchner.github.io/UltraNest/readme.html\n",
    "  \n",
    "Some reading on all is desired, we are going to cover just the basics below.\n",
    "\n",
    "Relevant bibliography for introduction to fitting X-ray data in a Bayesian framework: https://arxiv.org/abs/2309.05705\n",
    "\n",
    "Relevant bibliography on why reduced chi^2 is not a great method for this: https://arxiv.org/abs/1012.3754\n",
    "\n",
    "> **Note:**  In principle, one could use another Bayesian parameter inference software/technique. Here, we are using UltraNest, which employs the nested sampling method, but one could also use, e.g., emcee ( https://emcee.readthedocs.io/en/stable/ ), which employs Markov Chain Monte Carlo (MCMC) methods.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "594a9e08-405b-4009-8d5b-160c832594f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default fit statistic is set to: Chi-Squared\n",
      "   This will apply to all current and newly loaded spectra.\n"
     ]
    }
   ],
   "source": [
    "# General imports\n",
    "import os\n",
    "import numpy as np\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "\n",
    "# Setting cosmology\n",
    "cosmo = FlatLambdaCDM(H0=73, Om0=0.3, Tcmb0=2.725)\n",
    "\n",
    "# Xspec, BXA, and UltraNest imports and config\n",
    "from xspec import *\n",
    "Xset.chatter = 10  # Controls pyXPSEC output\n",
    "Xset.cosmo = \"73\"  # Cosmology for pyXPSEC\n",
    "import bxa.xspec as bxa\n",
    "bxa.BXASolver.allowed_stats.append(\"chi\")  # Enable Gaussian statistics\n",
    "from bxa.xspec.solver import set_parameters  # For later use\n",
    "Fit.statMethod = \"chi\"  # Set pyXPSEC statistics to Gaussian\n",
    "Fit.query = \"yes\"\n",
    "Plot.device = \"/xs\"  # Plotting console for pyXPSEC\n",
    "Plot.yLog = True\n",
    "Plot.background = True\n",
    "\n",
    "# Load diskSED model\n",
    "from diskSED import diskSED_info, diskSED\n",
    "AllModels.addPyMod(diskSED, diskSED_info(), 'add')  # Additive model\n",
    "\n",
    "# Load reddenSF model (Calzetti et al. attenuation law)\n",
    "from diskSED import reddenSF_info, reddenSF\n",
    "AllModels.addPyMod(reddenSF, reddenSF_info(), 'mul')  # Multiplicative model\n",
    "\n",
    "# Load reddenCCM model (CCM extinction law) This is the same as the XSPEC native 'redden' but extended to the Lyman limit.\n",
    "from diskSED import reddenCCM_info, reddenCCM\n",
    "AllModels.addPyMod(reddenCCM, reddenCCM_info(), 'mul')  # Multiplicative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c47f6698-c6b8-4662-8310-2ca381cd9a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Source redshift\n",
    "z = 0.0206\n",
    "\n",
    "# Galactic color excess at 14li's position \n",
    "E_BV_G = 0.022\n",
    "\n",
    "# Galactic column density at 14li's position (units of 10^22)\n",
    "N_H_G = 1.95E+20 / 1e22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf95a90e-e280-4305-b790-712d5127b38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Models will now use energy array created from:\n",
      "   0.0005 - 2   400 log bins\n",
      "\n",
      "***Warning: Unrecognized grouping for channel(s). It/they will be reset to 1.\n",
      "\n",
      "2 spectra  in use\n",
      " \n",
      "Spectral Data File: 14li_E1_grp.fits  Spectrum 1\n",
      "Net count rate (cts/s) for Spectrum:1  1.528e+00 +/- 6.581e-03 (98.9 % total)\n",
      " Assigned to Data Group 1 and Plot Group 1\n",
      "  Noticed Channels:  1-1189\n",
      "  Telescope: XMM Instrument: EPN  Channel Type: PI\n",
      "  Exposure Time: 3.574e+04 sec\n",
      " Using fit statistic: chi\n",
      " Using Background File                14li_E1_bkg.fits\n",
      "  Background Exposure Time: 3.574e+04 sec\n",
      " Using Response (RMF) File            14li_E1_rmf.fits for Source 1\n",
      "\n",
      "Spectral Data File: uvopt.pha  Spectrum 2\n",
      "Net count rate (cts/s) for Spectrum:2  6.010e-02 +/- 5.473e-03\n",
      " Assigned to Data Group 1 and Plot Group 2\n",
      "  Noticed Channels:  1-4\n",
      "  Telescope:  Instrument:   Channel Type: PI\n",
      "  Exposure Time: 1 sec\n",
      " Using fit statistic: chi\n",
      " Using Response (RMF) File            uvopt.rmf for Source 1\n",
      "\n",
      "Arf successfully loaded.\n",
      "     3 channels (1-3) ignored in spectrum #     1\n",
      "  1178 channels (12-1189) ignored in spectrum #     1\n",
      "\n",
      "Response successfully loaded.\n",
      "\n",
      "ignore:  1158 channels ignored from  source number 1\n",
      "ignore:     0 channels ignored from  source number 2\n"
     ]
    }
   ],
   "source": [
    "# Quick cleaning (in case something has been loaded already)\n",
    "AllData.clear()\n",
    "AllModels.clear()\n",
    "AllData.clear()\n",
    "\n",
    "Plot.xAxis = \"keV\"\n",
    "# Set energy bins for the model (working from 5e-4 keV to 2 keV with 400 log bins)\n",
    "AllModels.setEnergies('0.0005 2.0 400 log')\n",
    "\n",
    "# Load X-ray and UV/optical data\n",
    "E_lim = [0.25, 0.9]  # Energy limits for X-ray spectrum, use wathever criteria you think is resonable\n",
    "os.chdir(os.path.join(cwd, 'data', 'SED'))\n",
    "x_ray_file = '14li_E1_grp.fits'\n",
    "uvopt_file = 'uvopt.pha'\n",
    "AllData('1:1 ' + str(x_ray_file) + ' 1:2 ' + str(uvopt_file))\n",
    "\n",
    "# Ignore bad channels\n",
    "Xray = AllData(1)\n",
    "Xray.response.arf = '14li_E1_arf.fits' # Sometimes we need to add the arf manually, it fails to find automatically.\n",
    "Xray.ignore('0.0-' + str(E_lim[0]) + ' ' + str(E_lim[1]) + '-**')\n",
    "uvopt = AllData(2)\n",
    "uvopt.response = 'uvopt.rmf'\n",
    "AllData.ignore(\"bad\")\n",
    "\n",
    "#If you had another epoch you could use this to load it:\n",
    "'''\n",
    "E_lim  = [0.25, .8]\n",
    "os.chdir(os.path.join(cwd, 'data', 'SED2'))\n",
    "x_ray_file2 = '14li_E2_grp.fits'\n",
    "uvopt_file2 = 'uvopt2.pha'\n",
    "AllData('2:3 '+str(x_ray_file2) + ' 2:4 ' +str(uvopt_file2))\n",
    "Xray2 =  AllData(3)\n",
    "Xray2.ignore('0.0-'+ str(E_lim[0])+ ' '+ str(E_lim[1])+ '-**')\n",
    "uvopt2 = AllData(4)\n",
    "uvopt2.response = 'uvopt2.rmf'\n",
    "'''\n",
    "\n",
    "# Let's Plot the data\n",
    "Plot(\"data\") # Yes, the units look weird this way. But is just to make sure, it is all loaded. You see an X-ray spectrum (with background) and an opt/UV SED.\n",
    "\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f3e0ed1-9a0c-4348-a069-18e1da37eba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "Model phabs<1>*redden<2>*zashift<3>*phabs<4>*reddenSF<5>*diskSED<6> Source No.: 1   Active/On\n",
      "Model Model Component  Parameter  Unit     Value\n",
      " par  comp\n",
      "   1    1   phabs      nH         10^22    1.00000      +/-  0.0          \n",
      "   2    2   redden     E_BmV               5.00000E-02  +/-  0.0          \n",
      "   3    3   zashift    Redshift            0.0          frozen\n",
      "   4    4   phabs      nH         10^22    1.00000      +/-  0.0          \n",
      "   5    5   reddenSF   ebmv                1.00000E-03  +/-  0.0          \n",
      "   6    6   diskSED    R_in*      km       1.00000E+06  +/-  0.0          \n",
      "   7    6   diskSED    T_p        Kelvin   5.00000E+05  +/-  0.0          \n",
      "   8    6   diskSED    R_ratio             100.000      +/-  0.0          \n",
      "   9    6   diskSED    D_Mpc      Mpc      10.0000      +/-  0.0          \n",
      "  10    6   diskSED    norm                1.00000      +/-  0.0          \n",
      "________________________________________________________________________\n",
      "\n",
      "\n",
      "Fit statistic  : Chi-Squared                19993.90     using 8 bins, spectrum 1.\n",
      "                 Chi-Squared                  123.59     using 4 bins, spectrum 2.\n",
      "Total fit statistic                         20117.49     with 3 d.o.f.\n",
      "\n",
      "Test statistic : Chi-Squared                20117.49     using 12 bins.\n",
      " Null hypothesis probability of 0.00e+00 with 3 degrees of freedom\n",
      " Current data and model not fit yet.\n",
      "\n",
      "Parameters defined:\n",
      "========================================================================\n",
      "Model phabs<1>*redden<2>*zashift<3>*phabs<4>*reddenSF<5>*diskSED<6> Source No.: 1   Active/On\n",
      "Model Model Component  Parameter  Unit     Value\n",
      " par  comp\n",
      "   1    1   phabs      nH         10^22    1.00000      +/-  0.0          \n",
      "   2    2   redden     E_BmV               5.00000E-02  +/-  0.0          \n",
      "   3    3   zashift    Redshift            0.0          frozen\n",
      "   4    4   phabs      nH         10^22    1.00000      +/-  0.0          \n",
      "   5    5   reddenSF   ebmv                1.00000E-03  +/-  0.0          \n",
      "   6    6   diskSED    R_in*      km       1.00000E+06  +/-  0.0          \n",
      "   7    6   diskSED    T_p        Kelvin   5.00000E+05  +/-  0.0          \n",
      "   8    6   diskSED    R_ratio             100.000      +/-  0.0          \n",
      "   9    6   diskSED    D_Mpc      Mpc      10.0000      +/-  0.0          \n",
      "  10    6   diskSED    norm                1.00000      +/-  0.0          \n",
      "________________________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the model\n",
    "\n",
    "m = Model('phabs*redden*zashift*phabs*reddenSF*(diskSED)') \n",
    "# Please read arXiv:2408.17296 for a detailed description:\n",
    "# phabs*reddenCCM accounts for Galactic X-ray neutral gas absorption and Galactic dust extinction, respectively.\n",
    "# zashift redshifts the model.\n",
    "# phabs*reddenSF accounts for intrinsic X-ray neutral gas absorption and intrinsic dust attenuation, respectively.\n",
    "# Note: We use phabs instead of, e.g., tbabs, because tbabs corrects down to UV wavelengths (not only X-ray) and using it would result in double correction in the UV.\n",
    "\n",
    "AllModels.show() # The model components are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e735183-e9ef-4fd4-86bf-d3c5997c1b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fit statistic  : Chi-Squared                23297.00     using 8 bins, spectrum 1.\n",
      "                 Chi-Squared                  123.59     using 4 bins, spectrum 2.\n",
      "Total fit statistic                         23420.59     with 4 d.o.f.\n",
      "\n",
      "Test statistic : Chi-Squared                23420.59     using 12 bins.\n",
      " Null hypothesis probability of 0.00e+00 with 4 degrees of freedom\n",
      " Current data and model not fit yet.\n",
      "\n",
      "Fit statistic  : Chi-Squared                23297.00     using 8 bins, spectrum 1.\n",
      "                 Chi-Squared                  287.08     using 4 bins, spectrum 2.\n",
      "Total fit statistic                         23584.09     with 5 d.o.f.\n",
      "\n",
      "Test statistic : Chi-Squared                23584.09     using 12 bins.\n",
      " Null hypothesis probability of 0.00e+00 with 5 degrees of freedom\n",
      " Current data and model not fit yet.\n",
      "\n",
      "Fit statistic  : Chi-Squared                23477.64     using 8 bins, spectrum 1.\n",
      "                 Chi-Squared                  293.62     using 4 bins, spectrum 2.\n",
      "Total fit statistic                         23771.26     with 5 d.o.f.\n",
      "\n",
      "Test statistic : Chi-Squared                23771.26     using 12 bins.\n",
      " Null hypothesis probability of 0.00e+00 with 5 degrees of freedom\n",
      " Current data and model not fit yet.\n",
      "\n",
      "Fit statistic  : Chi-Squared              2.725005e+07     using 8 bins, spectrum 1.\n",
      "                 Chi-Squared                  293.62     using 4 bins, spectrum 2.\n",
      "Total fit statistic                       2.725034e+07     with 5 d.o.f.\n",
      "\n",
      "Test statistic : Chi-Squared              2.725034e+07     using 12 bins.\n",
      " Null hypothesis probability of 0.000000e+00 with 5 degrees of freedom\n",
      " Current data and model not fit yet.\n",
      "\n",
      "Fit statistic  : Chi-Squared              2.725005e+07     using 8 bins, spectrum 1.\n",
      "                 Chi-Squared                   78.72     using 4 bins, spectrum 2.\n",
      "Total fit statistic                       2.725013e+07     with 6 d.o.f.\n",
      "\n",
      "Test statistic : Chi-Squared              2.725013e+07     using 12 bins.\n",
      " Null hypothesis probability of 0.000000e+00 with 6 degrees of freedom\n",
      " Current data and model not fit yet.\n",
      "\n",
      "Fit statistic  : Chi-Squared              2.259215e+13     using 8 bins, spectrum 1.\n",
      "                 Chi-Squared              3.511992e+08     using 4 bins, spectrum 2.\n",
      "Total fit statistic                       2.259250e+13     with 6 d.o.f.\n",
      "\n",
      "Test statistic : Chi-Squared              2.259250e+13     using 12 bins.\n",
      " Null hypothesis probability of 0.000000e+00 with 6 degrees of freedom\n",
      " Current data and model not fit yet.\n",
      "\n",
      "Fit statistic  : Chi-Squared                43486.44     using 8 bins, spectrum 1.\n",
      "                 Chi-Squared              1.485419e+07     using 4 bins, spectrum 2.\n",
      "Total fit statistic                       1.489767e+07     with 6 d.o.f.\n",
      "\n",
      "Test statistic : Chi-Squared              1.489767e+07     using 12 bins.\n",
      " Null hypothesis probability of 0.000000e+00 with 6 degrees of freedom\n",
      " Current data and model not fit yet.\n",
      "\n",
      "Fit statistic  : Chi-Squared                43486.46     using 8 bins, spectrum 1.\n",
      "                 Chi-Squared                95555.77     using 4 bins, spectrum 2.\n",
      "Total fit statistic                         139042.2     with 6 d.o.f.\n",
      "\n",
      "Test statistic : Chi-Squared                139042.2     using 12 bins.\n",
      " Null hypothesis probability of 0.0e+00 with 6 degrees of freedom\n",
      " Current data and model not fit yet.\n",
      "\n",
      "Fit statistic  : Chi-Squared                18764.23     using 8 bins, spectrum 1.\n",
      "                 Chi-Squared                   60.70     using 4 bins, spectrum 2.\n",
      "Total fit statistic                         18824.93     with 7 d.o.f.\n",
      "\n",
      "Test statistic : Chi-Squared                18824.93     using 12 bins.\n",
      " Null hypothesis probability of 0.00e+00 with 7 degrees of freedom\n",
      " Current data and model not fit yet.\n",
      "\n",
      "Fit statistic  : Chi-Squared                18764.23     using 8 bins, spectrum 1.\n",
      "                 Chi-Squared                   60.70     using 4 bins, spectrum 2.\n",
      "Total fit statistic                         18824.93     with 8 d.o.f.\n",
      "\n",
      "Test statistic : Chi-Squared                18824.93     using 12 bins.\n",
      " Null hypothesis probability of 0.00e+00 with 8 degrees of freedom\n",
      " Current data and model not fit yet.\n",
      "\n",
      "Parameters defined:\n",
      "========================================================================\n",
      "Model phabs<1>*redden<2>*zashift<3>*phabs<4>*reddenSF<5>*diskSED<6> Source No.: 1   Active/On\n",
      "Model Model Component  Parameter  Unit     Value\n",
      " par  comp\n",
      "   1    1   phabs      nH         10^22    1.95000E-02  frozen\n",
      "   2    2   redden     E_BmV               2.20000E-02  frozen\n",
      "   3    3   zashift    Redshift            2.06000E-02  frozen\n",
      "   4    4   phabs      nH         10^22    4.00000E-02  +/-  0.0          \n",
      "   5    5   reddenSF   ebmv                4.46902E-02  = p4*1e22/8.9505e21\n",
      "   6    6   diskSED    R_in*      km       3.00000E+07  +/-  0.0          \n",
      "   7    6   diskSED    T_p        Kelvin   2.00000E+05  +/-  0.0          \n",
      "   8    6   diskSED    R_ratio             10.0000      +/-  0.0          \n",
      "   9    6   diskSED    D_Mpc      Mpc      85.9396      frozen\n",
      "  10    6   diskSED    norm                1.00000      frozen\n",
      "________________________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's edit these parameters, fix what needs to be fixed, and add reasonable ranges to those that will be fitted.\n",
    "\n",
    "# phabs Nh\n",
    "AllModels(1)(1).values = (N_H_G, -1)  # Fixing\n",
    "\n",
    "# reddenCCM\n",
    "AllModels(1)(2).values = (E_BV_G, -1) # This assumes a Galactic Gas-to-dust Ratio with R_v  = 3.1. See comments below. \n",
    "\n",
    "# zashift Redshift\n",
    "AllModels(1)(3).values = (z, -1)  # Fixing\n",
    "\n",
    "# phabs Nh\n",
    "AllModels(1)(4).values = (0.04, 0.001, 0.02, 0.02, 0.1, 0.1)  \n",
    "# Check the pyxspec manual for the meaning of each of the six entries. The first entry is the initial guess, but that is not used in a Bayesian fitting.\n",
    "\n",
    "# redden\n",
    "AllModels(1)(5).link = '4 * 1e22 / 8.9505e21'  \n",
    "# Linking intrinsic E(B-V) (parameter 5) to intrinsic N_H (parameter 4). \n",
    "# Assumes a Galactic Gas-to-Dust Ratio (https://arxiv.org/abs/0903.2057) with R_v = 4.05 (consistent with Calzetti's law).\n",
    "# You could also make this free or use, e.g., a Gaussian prior centered around an independent estimate \n",
    "# for the intrinsic E(B-V), such as from the Balmer decrement of the nuclear optical spectrum of the source.\n",
    "\n",
    "# Parameters for diskSED. Feel free to modify give the expectations from your source/observations; note that larger ranges will increase convergence time.\n",
    "\n",
    "# diskSED R_in*: Expected range for the Rin* parameter in km.\n",
    "AllModels(1)(6).values = (3e7, 10, 3e7, 3e7, 1e8, 1e8)\n",
    "\n",
    "# diskSED T_p: Expected range for inner disk temperature in Kelvin.\n",
    "AllModels(1)(7).values = (2e5, 1e-2, 1e5, 1e5, 1e6, 1e6)\n",
    "\n",
    "# diskSED R_ratio: Expected outer-to-inner radius ratio range.\n",
    "AllModels(1)(8).values = (10, 1e-1, 5, 5, 30, 30)\n",
    "\n",
    "# diskSED Distance: Distance to the source in Mpc. Needs to be fixed.\n",
    "AllModels(1)(9).values = (cosmo.luminosity_distance(z).to('Mpc').value, -1)\n",
    "\n",
    "# diskSED norm: This must always be set to 1.\n",
    "AllModels(1)(10).values = (1, -1)  \n",
    "# Rin* is already the normalization parameter of the model.\n",
    "\n",
    "# Check the model below; there should be exactly 4 free parameters, and 2 Tied.\n",
    "AllModels.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4033f6-a488-4dc1-bab3-c711807c65aa",
   "metadata": {},
   "source": [
    "# Preparing the statistics for the fitting:\n",
    "\n",
    "Here we have two options:\n",
    "\n",
    "i) use BXA to create the priors, prior transformations (it has some option: e.g. uniform, log-uniform, and gaussian) and the likehood function. This should help undertand BXA better: https://peterboorman.com/xsf22\n",
    "\n",
    "ii) Or create our own prior, prior transformation and likehood functions from scratch, details on how to to that are avalible in the UltraNest page: https://johannesbuchner.github.io/UltraNest/using-ultranest.html\n",
    "\n",
    "I will examplify both below, for very simple linear/log-linear priors and Gaussian likehood. In general we will use the BXA tools, we may want to do from scratch if we want special priors (besides uniform, log-uniform, or Gaussian) which are not included in BXA, or if we wanna make more complex likehood functions, e.g. add upper limits, or combine Gaussian and Poisson statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2b934b1-ef57-4976-95dc-a0d27c6448c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  uniform prior for nH between 0.020000 and 0.100000 \n",
      "  jeffreys prior for R_in* between 3.000000e+07 and 1.000000e+08 \n",
      "  uniform prior for T_p between 100000.000000 and 1000000.000000 \n",
      "  uniform prior for R_ratio between 5.000000 and 30.000000 \n",
      "------------------------------------------\n",
      "['nH', 'log(R_in*)', 'T_p', 'R_ratio']\n"
     ]
    }
   ],
   "source": [
    "# Using BXA:\n",
    "\n",
    "# These creates the priors\n",
    "prior_NH = bxa.create_uniform_prior_for(AllModels(1), AllModels(1)(4)) # The number 1 is the data group (here we only have 1), while the other number is the paramter order, e.g. 4, see above. See BXA tutorial for details.\n",
    "prior_R = bxa.create_loguniform_prior_for(AllModels(1), AllModels(1)(6))\n",
    "prior_T = bxa.create_uniform_prior_for(AllModels(1), AllModels(1)(7))\n",
    "prior_R_ratio = bxa.create_uniform_prior_for(AllModels(1), AllModels(1)(8))\n",
    "\n",
    "# This creates all the rest\n",
    "solver = bxa.BXASolver(transformations=[prior_NH, prior_R, prior_T, prior_R_ratio])\n",
    "\n",
    "# Define/load here\n",
    "paramnames_bxa = solver.paramnames\n",
    "prior_bxa  = solver.prior_function\n",
    "loglike_bxa  = solver.log_likelihood\n",
    "prior_transform_bxa = solver.transformations\n",
    "\n",
    "print('------------------------------------------')\n",
    "print(paramnames_bxa) # This is just a list with name of paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0ae1756-2d91-4e97-ae77-8fc6074111aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating from scratch. THIS IS ADVANCED USE, skip this cell and use the BXA ready functions, if you just wanna do your first run. \n",
    "\n",
    "# Paremeters names\n",
    "paramnames = ['nH', 'log(R_in*)', 'T_p', 'R_ratio']\n",
    "\n",
    "# Creating priors\n",
    "\n",
    "def create_uniform_prior_for(model, par):\n",
    "\tpval, pdelta, pmin, pbottom, ptop, pmax = par.values\n",
    "\tlow = float(pmin)\n",
    "\tspread = float(pmax - pmin)\n",
    "\tdef uniform_transform(x): return x * spread + low\n",
    "\treturn dict(model=model, index=par._Parameter__index, name=par.name, transform=uniform_transform, aftertransform=lambda x: x)\n",
    "    \n",
    "\n",
    "def create_loguniform_prior_for(model, par):\n",
    "\tpval, pdelta, pmin, pbottom, ptop, pmax = par.values\n",
    "\tlow = np.log10(pmin)\n",
    "\tspread = np.log10(pmax) - np.log10(pmin)\n",
    "\tdef log_transform(x): return x * spread + low\n",
    "\tdef log_after_transform(x): return 10**x\n",
    "\treturn dict(model=model, index=par._Parameter__index, name='log(%s)' % par.name, transform=log_transform, aftertransform=log_after_transform)\n",
    "\n",
    "\n",
    "prior_NH = create_uniform_prior_for(AllModels(1), AllModels(1)(4))\n",
    "prior_R = create_loguniform_prior_for(AllModels(1), AllModels(1)(6))\n",
    "prior_T = create_uniform_prior_for(AllModels(1), AllModels(1)(7))\n",
    "prior_R_ratio = create_uniform_prior_for(AllModels(1), AllModels(1)(8))\n",
    "prior_transform=[prior_NH, prior_R,prior_T,prior_R_ratio ]\n",
    "\n",
    "# Creating prior transformations (see UltraNest tutorial for deeper undertanding)\n",
    "\n",
    "def create_prior_function(transformations):\n",
    "\t\"\"\"\n",
    "\tCreate a single prior transformation function from a list of\n",
    "\ttransformations for each parameter. This assumes the priors factorize.\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef prior(cube):\n",
    "\t\tparams = cube.copy()\n",
    "\t\tfor i, t in enumerate(transformations):\n",
    "\t\t\ttransform = t['transform']\n",
    "\t\t\tparams[i] = transform(cube[i])\n",
    "\t\treturn params\n",
    "\n",
    "\treturn prior  \n",
    "\n",
    "prior = create_prior_function(prior_transform)\n",
    "\n",
    "# Creating a log-likehood function\n",
    "def log_likelihood(params):\n",
    "    \"\"\" returns -0.5 of the fit statistic.\"\"\"\n",
    "    set_parameters(transformations=prior_transform, values=params) # This simple set all the free prameter to a given array 'params'\n",
    "    like = -0.5 * Fit.statistic # Fit statistics here, simple return the current statistics of the model , i.e. SUM ((data-model)/error)^2\n",
    "    if not np.isfinite(like): # Just check if it is finite\n",
    "        return -1e100\n",
    "    return like\n",
    "\n",
    "loglike = log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7c9446d-29f7-4fdc-9eea-14c3bb6cb267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ultranest] Sampling 200 live points from prior ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5893c7cf34d34390ba7475a725ffd8ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), GridspecLayout(children=(HTML(value=\"<div style='background-color:#6E6BF4;'>&nb…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ultranest] Explored until L=-4  33 [-4.4753..-4.4752]*| it/evals=3996/12690 eff=31.9936% N=200              00 0 0   \n",
      "[ultranest] Likelihood function evaluations: 12690\n",
      "[ultranest] Writing samples and results to disk ...\n",
      "[ultranest] Writing samples and results to disk ... done\n",
      "[ultranest]   logZ = -19.76 +- 0.1689\n",
      "[ultranest] Effective samples strategy satisfied (ESS = 1072.7, need >400)\n",
      "[ultranest] Posterior uncertainty strategy is satisfied (KL: 0.45+-0.07 nat, need <0.50 nat)\n",
      "[ultranest] Evidency uncertainty strategy is satisfied (dlogz=0.17, need <0.5)\n",
      "[ultranest]   logZ error budget: single: 0.26 bs:0.17 tail:0.01 total:0.17 required:<0.50\n",
      "[ultranest] done iterating.\n",
      "\n",
      "logZ = -19.801 +- 0.376\n",
      "  single instance: logZ = -19.801 +- 0.260\n",
      "  bootstrapped   : logZ = -19.763 +- 0.376\n",
      "  tail           : logZ = +- 0.010\n",
      "insert order U test : converged: True correlation: inf iterations\n",
      "\n",
      "    nH                  : 0.0252│ ▁▁ ▁▁▁▁▁▂▂▂▃▄▄▅▇▇▇▇▆▆▅▄▃▃▃▂▂▁▁▁▁▁▁▁ ▁ │0.0624    0.0434 +- 0.0047\n",
      "    log(R_in*)          : 7.524 │ ▁ ▁▁▁▁▁▁▁▂▂▂▄▅▄▆▆▇▇▇▅▅▄▄▃▃▂▁▁▁▁▁ ▁▁ ▁ │7.934     7.729 +- 0.048\n",
      "    T_p                 : 225949│ ▁ ▁▁▁▁▁▁▁▂▃▃▄▅▆▇▇▇▇▇▆▆▅▄▂▂▂▁▁▁▁▁ ▁  ▁ │252485    238657 +- 3010\n",
      "    R_ratio             : 6.13  │ ▁▁▁▁▂▂▃▃▅▅▅▆▆▇▇▇▆▆▅▄▃▃▃▁▂▂▁▁▁▁ ▁▁▁  ▁ │13.79     9.13 +- 0.98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OK, now we can run some Baeysian inference. I will use UltraNest.\n",
    "import ultranest\n",
    "from ultranest import ReactiveNestedSampler\n",
    "import pandas as pd\n",
    "# We wanna make pyXSPEC quiet now. So just Ultranest can display progress.\n",
    "Xset.chatter = 1\n",
    "\n",
    "os.chdir(os.path.join(cwd, 'data')) # make sure we are where we want.\n",
    "outputfiles_basename = 'diskSED_run' # Name of the folder we gonna save the sampling results\n",
    "\n",
    "#picking BXA funcitons\n",
    "sampler = ReactiveNestedSampler(paramnames_bxa, loglike_bxa, prior_bxa, log_dir=outputfiles_basename, resume='overwrite')\n",
    "\n",
    "#picking our own funcitons\n",
    "#sampler = ReactiveNestedSampler(paramnames, loglike, prior, log_dir=outputfiles_basename, resume='overwrite')\n",
    "\n",
    "result = sampler.run(frac_remain=1e-2, min_num_live_points=200,min_ess=400) # See UltraNest for details on what the varaibles mean. These are standard values. \n",
    "# Some intuition: \n",
    "# decreasing frac_remain (e.g. to 5e-2, or 1e-1) wil make the sampling finish earlier, running longer does not mean necessarily a better fit.\n",
    "# decreasing min_num_live_points decreases the 'resolution' of the sampling, but makes the computations faster.\n",
    "\n",
    "sampler.print_results() # print final results\n",
    "sampler.plot() # makes some standard corner, and tracer plots\n",
    "\n",
    "posterior_df = pd.DataFrame(data=result[\"samples\"], columns=solver.paramnames)\n",
    "posterior_df.to_csv(os.path.join(cwd, 'data', \"%s/posterior.csv\" %(outputfiles_basename)), index=False) # Just saving the posterior into a .csv file, cause it is easier.\n",
    "\n",
    "# This will run and save the results inside a 'diskSED_run' folder.\n",
    "# It will take time (10-20 min). If you wanna speed up things, e.g. by running in multiple cores. There will be a 'fitting.py' script, which we can parallelize with MPI (https://www.open-mpi.org).\n",
    "# In the terminal, inside the examples folder, just do 'mpiexec -N X python3 fitting.py' where X is the number of cores you wanna run the sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7440e768-1c7c-4492-a94b-f8aeec2b2f33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eb1e3a-373e-4fd0-aa4a-dfa5b4848e87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
